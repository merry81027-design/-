import streamlit as st
import pandas as pd

# ==========================================
# 1. ç¶²é åŸºæœ¬è¨­å®š
# ==========================================
st.set_page_config(page_title="å€‹äººç”³è«‹æœ€ä½éŒ„å–åˆ†æ•¸æŸ¥è©¢ç³»çµ±", page_icon="ğŸ“", layout="centered")
st.title("ğŸ“ 112-114 å€‹ç”³æœ€ä½éŒ„å–åˆ†æ•¸æŸ¥è©¢")
st.markdown("ğŸ’¡ **æœå°‹æŠ€å·§**ï¼šé—œéµå­—æœå°‹ä¸åˆ°æ™‚è«‹æ‰“æ ¡ç³»å…¨åï¼Œä¸­é–“ç•™ç©ºæ ¼ï¼Œä¾‹å¦‚è¼¸å…¥ `åœ‹ç«‹è‡ºç£å¤§å­¸ è³‡è¨Šå·¥ç¨‹å­¸ç³»`ã€‚è³‡æ–™èˆ‡é›²ç«¯è©¦ç®—è¡¨å³æ™‚åŒæ­¥ï¼")
st.divider()

# ==========================================
# 2. é€£çµ Google è©¦ç®—è¡¨ (å³æ™‚è®€å–)
# ==========================================
# ğŸ”´ è€å¸«è«‹æ³¨æ„ï¼šè«‹æŠŠä¸‹é¢çš„å¼•è™Ÿå…§å®¹ï¼Œæ›æˆæ‚¨å‰›å‰›è¤‡è£½çš„ã€Œè³‡æ–™åº« IDã€ï¼
SHEET_ID = "1VVm5MkdMzYF80dngcnHiBIWz7D1Sh0BnQeRvlKlA9DA" 
URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv"

# è¨­å®šå¿«å–æ™‚é–“ç‚º 10 ç§’ (ttl=10)ã€‚ä»£è¡¨æ‚¨åœ¨ Excel æ”¹å®Œè³‡æ–™ï¼Œç¶²é æœ€å¤š 10 ç§’å¾Œå°±æœƒæ›´æ–°ï¼
@st.cache_data(ttl=10)
def load_data(url):
    df = pd.read_csv(url, dtype={'å­¸å¹´åº¦': str, 'ç³»æ ¡ä»£ç¢¼': str})
    df = df.dropna(subset=['ç³»æ ¡ä»£ç¢¼'])
    return df

try:
    with st.spinner("ğŸ”„ æ­£åœ¨èˆ‡é›²ç«¯è³‡æ–™åº«åŒæ­¥ä¸­..."):
        df = load_data(URL)
except Exception as e:
    st.error("âŒ ç„¡æ³•è®€å–è³‡æ–™åº«ï¼Œè«‹ç¢ºèª Google è©¦ç®—è¡¨æ¬Šé™ã€‚")
    st.stop()

# ==========================================
# 3. ç¶²é æœå°‹ä»‹é¢èˆ‡ã€Œæ ¡åç¿»è­¯è’Ÿè’»ã€
# ==========================================
# å»ºç«‹å¸¸è¦‹å¤§å­¸ç°¡ç¨±å­—å…¸
alias_dict = {
    "å°å¤§": "è‡ºç£å¤§å­¸",
    "è‡ºå¤§": "è‡ºç£å¤§å­¸",
    "æ”¿å¤§": "æ”¿æ²»å¤§å­¸",
    "æ¸…å¤§": "æ¸…è¯å¤§å­¸",
    "äº¤å¤§": "äº¤é€šå¤§å­¸",
    "é™½äº¤å¤§": "é™½æ˜äº¤é€šå¤§å­¸",
    "æˆå¤§": "æˆåŠŸå¤§å­¸",
    "å¸«å¤§": "å¸«ç¯„å¤§å­¸", 
    "å°å¸«å¤§": "è‡ºç£å¸«ç¯„å¤§å­¸",
    "è‡ºå¸«å¤§": "è‡ºç£å¸«ç¯„å¤§å­¸",
    "å½°å¸«å¤§": "å½°åŒ–å¸«ç¯„å¤§å­¸",
    "é«˜å¸«å¤§": "é«˜é›„å¸«ç¯„å¤§å­¸",
    "åœ‹åŒ—æ•™": "è‡ºåŒ—æ•™è‚²å¤§å­¸",
    "åœ‹åŒ—è­·": "è‡ºåŒ—è­·ç†å¥åº·å¤§å­¸",
    "å¸‚åŒ—æ•™": "è‡ºåŒ—å¸‚ç«‹å¤§å­¸",
    "ä¸­æ•™å¤§": "è‡ºä¸­æ•™è‚²å¤§å­¸",
    "åŒ—å¤§": "è‡ºåŒ—å¤§å­¸",
    "æµ·å¤§": "æµ·æ´‹å¤§å­¸",
    "å°ç§‘å¤§": "è‡ºç£ç§‘æŠ€å¤§å­¸",
    "è‡ºç§‘å¤§": "è‡ºç£ç§‘æŠ€å¤§å­¸",
    "åŒ—ç§‘å¤§": "è‡ºåŒ—ç§‘æŠ€å¤§å­¸",
    "æš¨å¤§": "æš¨å—åœ‹éš›å¤§å­¸",
    "æ±è¯": "æ±è¯å¤§å­¸",
    "é«˜å¤§": "é«˜é›„å¤§å­¸",
    "ä¸­å±±": "ä¸­å±±å¤§å­¸",
    "ä¸­å¤®": "ä¸­å¤®å¤§å­¸",
    "ä¸­æ­£": "ä¸­æ­£å¤§å­¸",
    "ä¸­èˆˆ": "ä¸­èˆˆå¤§å­¸",
    "é•·åºš": "é•·åºšå¤§å­¸",
    "é«˜é†«": "é«˜é›„é†«å­¸å¤§å­¸",
    "ä¸­åœ‹é†«": "ä¸­åœ‹é†«è—¥å¤§å­¸",
    "ä¸­å±±é†«": "ä¸­å±±é†«å­¸å¤§å­¸",
    "åŒ—é†«": "è‡ºåŒ—é†«å­¸å¤§å­¸"
}

user_input = st.text_input("ğŸ” è«‹è¼¸å…¥å­¸æ ¡æˆ–ç§‘ç³»é—œéµå­—ï¼š", placeholder="ä¾‹å¦‚ï¼šæ”¿å¤§ å¿ƒç†")

if user_input:
    # --- æ­¥é©Ÿ A: å°‡ä½¿ç”¨è€…çš„ç°¡ç¨±ç¿»è­¯æˆæ­£å¼å…¨å ---
    search_query = user_input.replace('å°', 'è‡º') # å…ˆçµ±ä¸€å°‡å°è½‰æˆè‡º
    
   # æƒæå­—å…¸ (åŠ å…¥ sorted ç¢ºä¿å…ˆæ›¿æ›åå­—é•·çš„ï¼Œé¿å…ã€Œé«˜å¸«å¤§ã€è¢«ã€Œå¸«å¤§ã€æ””æˆª)
    for short_name in sorted(alias_dict.keys(), key=len, reverse=True):
        full_name = alias_dict[short_name]
        if short_name in search_query:
            search_query = search_query.replace(short_name, full_name)
            
    # åˆ‡å‰²é—œéµå­— (ä¾‹å¦‚ "æ”¿æ²»å¤§å­¸ å¿ƒç†" è®Šæˆ ["æ”¿æ²»å¤§å­¸", "å¿ƒç†"])
    keywords = search_query.split()
    
    # --- æ­¥é©Ÿ B: åŸ·è¡Œæœå°‹ ---
    df['full_text'] = df['å­¸æ ¡åç¨±'].astype(str) + " " + df['æ ¡ç³»åç¨±'].astype(str)
    
    mask = pd.Series([True] * len(df))
    for k in keywords:
        mask = mask & df['full_text'].str.contains(k, na=False)
        
    candidates = df[mask]
    
    # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œç”¨åŸå§‹å­—ä¸²å†è©¦ä¸€æ¬¡ä¿éšª
    if candidates.empty:
        raw_keywords = user_input.split()
        mask_retry = pd.Series([True] * len(df))
        for k in raw_keywords:
            mask_retry = mask_retry & df['full_text'].str.contains(k, na=False)
        candidates = df[mask_retry]

    # --- æ­¥é©Ÿ C: é¡¯ç¤ºçµæœ ---
    if candidates.empty:
        st.warning(f"âš ï¸ æ‰¾ä¸åˆ°åŒ…å«ã€Œ{user_input}ã€çš„ç§‘ç³»ï¼Œè«‹å˜—è©¦æ›´æ›æˆ–ç¸®çŸ­é—œéµå­—ã€‚")
    else:
        target_codes = candidates['ç³»æ ¡ä»£ç¢¼'].unique()
        st.success(f"ğŸ¯ æ‰¾åˆ° {len(target_codes)} å€‹ç›¸é—œç§‘ç³»ï¼")
        
        for code in target_codes:
            history_data = df[df['ç³»æ ¡ä»£ç¢¼'] == code]
            history_data = history_data.sort_values(by='å­¸å¹´åº¦', ascending=False)
            
            school_name = history_data.iloc[0]['å­¸æ ¡åç¨±']
            dept_names = history_data['æ ¡ç³»åç¨±'].unique()
            dept_name_display = " / ".join(dept_names)
            
            st.subheader(f"ğŸ« ã€{school_name}ã€‘")
            st.caption(f"ğŸ“Œ ç³»åç´€éŒ„ï¼š{dept_name_display} (ä»£ç¢¼ï¼š{code})")
            
            cols = ['å­¸å¹´åº¦', 'æ ¡ç³»åç¨±', 'æ‹›ç”Ÿåé¡', 'ç¯©é¸ä¸€', 'ç¯©é¸äºŒ', 'ç¯©é¸ä¸‰', 'ç¯©é¸å››', 'ç¯©é¸äº”']
            show_cols = [c for c in cols if c in history_data.columns]
            
            st.dataframe(history_data[show_cols], hide_index=True, use_container_width=True)
            st.divider()
